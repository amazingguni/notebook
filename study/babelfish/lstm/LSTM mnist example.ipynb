{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnist data\n",
    "\n",
    "mnist에서 28개씩을 rnn으로 계산하는 예제\n",
    "\n",
    "\n",
    "\n",
    "## RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 128, Minibatch Loss= 2.655640, Training Accuracy= 0.14062\n",
      "Iter 512, Minibatch Loss= 2.104986, Training Accuracy= 0.32031\n",
      "Iter 640, Minibatch Loss= 2.090425, Training Accuracy= 0.26562\n",
      "Iter 2048, Minibatch Loss= 1.385004, Training Accuracy= 0.57031\n",
      "Iter 2176, Minibatch Loss= 1.266611, Training Accuracy= 0.60156\n",
      "Iter 2560, Minibatch Loss= 1.123744, Training Accuracy= 0.61719\n",
      "Iter 2688, Minibatch Loss= 1.100890, Training Accuracy= 0.61719\n",
      "Iter 4096, Minibatch Loss= 0.877658, Training Accuracy= 0.69531\n",
      "Iter 4224, Minibatch Loss= 0.902063, Training Accuracy= 0.71875\n",
      "Iter 4608, Minibatch Loss= 1.026876, Training Accuracy= 0.66406\n",
      "Iter 4736, Minibatch Loss= 0.785482, Training Accuracy= 0.71875\n",
      "Iter 6144, Minibatch Loss= 0.703815, Training Accuracy= 0.76562\n",
      "Iter 6272, Minibatch Loss= 0.725329, Training Accuracy= 0.74219\n",
      "Iter 6656, Minibatch Loss= 1.087749, Training Accuracy= 0.67188\n",
      "Iter 6784, Minibatch Loss= 0.805038, Training Accuracy= 0.79688\n",
      "Iter 8192, Minibatch Loss= 1.192677, Training Accuracy= 0.67969\n",
      "Iter 8320, Minibatch Loss= 0.642096, Training Accuracy= 0.76562\n",
      "Iter 8704, Minibatch Loss= 0.738639, Training Accuracy= 0.75781\n",
      "Iter 8832, Minibatch Loss= 0.826395, Training Accuracy= 0.69531\n",
      "Iter 10240, Minibatch Loss= 0.607818, Training Accuracy= 0.79688\n",
      "Iter 10368, Minibatch Loss= 0.542018, Training Accuracy= 0.84375\n",
      "Iter 10752, Minibatch Loss= 0.737334, Training Accuracy= 0.79688\n",
      "Iter 10880, Minibatch Loss= 0.872847, Training Accuracy= 0.73438\n",
      "Iter 12288, Minibatch Loss= 0.588613, Training Accuracy= 0.81250\n",
      "Iter 12416, Minibatch Loss= 0.597686, Training Accuracy= 0.78125\n",
      "Iter 12800, Minibatch Loss= 0.641457, Training Accuracy= 0.78906\n",
      "Iter 12928, Minibatch Loss= 0.681914, Training Accuracy= 0.77344\n",
      "Iter 14336, Minibatch Loss= 0.643249, Training Accuracy= 0.78906\n",
      "Iter 14464, Minibatch Loss= 0.419094, Training Accuracy= 0.86719\n",
      "Iter 14848, Minibatch Loss= 0.402592, Training Accuracy= 0.92188\n",
      "Iter 14976, Minibatch Loss= 0.461722, Training Accuracy= 0.82031\n",
      "Iter 16384, Minibatch Loss= 0.518936, Training Accuracy= 0.84375\n",
      "Iter 16512, Minibatch Loss= 0.476710, Training Accuracy= 0.84375\n",
      "Iter 16896, Minibatch Loss= 0.374041, Training Accuracy= 0.86719\n",
      "Iter 17024, Minibatch Loss= 0.384353, Training Accuracy= 0.88281\n",
      "Iter 18432, Minibatch Loss= 0.362762, Training Accuracy= 0.90625\n",
      "Iter 18560, Minibatch Loss= 0.399960, Training Accuracy= 0.83594\n",
      "Iter 18944, Minibatch Loss= 0.474059, Training Accuracy= 0.86719\n",
      "Iter 19072, Minibatch Loss= 0.484232, Training Accuracy= 0.82812\n",
      "Iter 20480, Minibatch Loss= 0.261495, Training Accuracy= 0.90625\n",
      "Iter 20608, Minibatch Loss= 0.453442, Training Accuracy= 0.86719\n",
      "Iter 20992, Minibatch Loss= 0.534572, Training Accuracy= 0.82031\n",
      "Iter 21120, Minibatch Loss= 0.365223, Training Accuracy= 0.89062\n",
      "Iter 22528, Minibatch Loss= 0.516092, Training Accuracy= 0.85938\n",
      "Iter 22656, Minibatch Loss= 0.312038, Training Accuracy= 0.90625\n",
      "Iter 23040, Minibatch Loss= 0.386047, Training Accuracy= 0.90625\n",
      "Iter 23168, Minibatch Loss= 0.393051, Training Accuracy= 0.89844\n",
      "Iter 24576, Minibatch Loss= 0.605524, Training Accuracy= 0.80469\n",
      "Iter 24704, Minibatch Loss= 0.431156, Training Accuracy= 0.83594\n",
      "Iter 25088, Minibatch Loss= 0.704108, Training Accuracy= 0.76562\n",
      "Iter 25216, Minibatch Loss= 0.703978, Training Accuracy= 0.78906\n",
      "Iter 26624, Minibatch Loss= 0.380305, Training Accuracy= 0.89844\n",
      "Iter 26752, Minibatch Loss= 0.755468, Training Accuracy= 0.79688\n",
      "Iter 27136, Minibatch Loss= 0.575887, Training Accuracy= 0.82031\n",
      "Iter 27264, Minibatch Loss= 0.563418, Training Accuracy= 0.82031\n",
      "Iter 28672, Minibatch Loss= 0.331732, Training Accuracy= 0.89062\n",
      "Iter 28800, Minibatch Loss= 0.364378, Training Accuracy= 0.88281\n",
      "Iter 29184, Minibatch Loss= 0.284580, Training Accuracy= 0.89062\n",
      "Iter 29312, Minibatch Loss= 0.235823, Training Accuracy= 0.92188\n",
      "Iter 30720, Minibatch Loss= 0.347098, Training Accuracy= 0.88281\n",
      "Iter 30848, Minibatch Loss= 0.187589, Training Accuracy= 0.95312\n",
      "Iter 31232, Minibatch Loss= 0.336791, Training Accuracy= 0.89844\n",
      "Iter 31360, Minibatch Loss= 0.329789, Training Accuracy= 0.90625\n",
      "Iter 32768, Minibatch Loss= 0.457030, Training Accuracy= 0.85156\n",
      "Iter 32896, Minibatch Loss= 0.419465, Training Accuracy= 0.88281\n",
      "Iter 33280, Minibatch Loss= 0.514903, Training Accuracy= 0.83594\n",
      "Iter 33408, Minibatch Loss= 0.275889, Training Accuracy= 0.90625\n",
      "Iter 34816, Minibatch Loss= 0.337862, Training Accuracy= 0.91406\n",
      "Iter 34944, Minibatch Loss= 0.419668, Training Accuracy= 0.85156\n",
      "Iter 35328, Minibatch Loss= 0.332124, Training Accuracy= 0.89844\n",
      "Iter 35456, Minibatch Loss= 0.353161, Training Accuracy= 0.91406\n",
      "Iter 36864, Minibatch Loss= 0.317698, Training Accuracy= 0.89844\n",
      "Iter 36992, Minibatch Loss= 0.252973, Training Accuracy= 0.94531\n",
      "Iter 37376, Minibatch Loss= 0.309118, Training Accuracy= 0.89844\n",
      "Iter 37504, Minibatch Loss= 0.685640, Training Accuracy= 0.84375\n",
      "Iter 38912, Minibatch Loss= 0.320696, Training Accuracy= 0.86719\n",
      "Iter 39040, Minibatch Loss= 0.417199, Training Accuracy= 0.92969\n",
      "Iter 39424, Minibatch Loss= 0.432404, Training Accuracy= 0.85938\n",
      "Iter 39552, Minibatch Loss= 0.418795, Training Accuracy= 0.89844\n",
      "Iter 40960, Minibatch Loss= 0.451311, Training Accuracy= 0.83594\n",
      "Iter 41088, Minibatch Loss= 0.474359, Training Accuracy= 0.86719\n",
      "Iter 41472, Minibatch Loss= 0.366355, Training Accuracy= 0.89062\n",
      "Iter 41600, Minibatch Loss= 0.210319, Training Accuracy= 0.89062\n",
      "Iter 43008, Minibatch Loss= 0.517130, Training Accuracy= 0.85938\n",
      "Iter 43136, Minibatch Loss= 0.299625, Training Accuracy= 0.93750\n",
      "Iter 43520, Minibatch Loss= 0.205769, Training Accuracy= 0.92969\n",
      "Iter 43648, Minibatch Loss= 0.275449, Training Accuracy= 0.91406\n",
      "Iter 45056, Minibatch Loss= 0.246890, Training Accuracy= 0.91406\n",
      "Iter 45184, Minibatch Loss= 0.291860, Training Accuracy= 0.88281\n",
      "Iter 45568, Minibatch Loss= 0.348577, Training Accuracy= 0.89844\n",
      "Iter 45696, Minibatch Loss= 0.367282, Training Accuracy= 0.88281\n",
      "Iter 47104, Minibatch Loss= 0.299227, Training Accuracy= 0.90625\n",
      "Iter 47232, Minibatch Loss= 0.498750, Training Accuracy= 0.82031\n",
      "Iter 47616, Minibatch Loss= 0.224093, Training Accuracy= 0.92969\n",
      "Iter 47744, Minibatch Loss= 0.447050, Training Accuracy= 0.85156\n",
      "Iter 49152, Minibatch Loss= 0.287130, Training Accuracy= 0.87500\n",
      "Iter 49280, Minibatch Loss= 0.202773, Training Accuracy= 0.93750\n",
      "Iter 49664, Minibatch Loss= 0.223946, Training Accuracy= 0.95312\n",
      "Iter 49792, Minibatch Loss= 0.232777, Training Accuracy= 0.92969\n",
      "Iter 51200, Minibatch Loss= 0.219870, Training Accuracy= 0.91406\n",
      "Iter 51328, Minibatch Loss= 0.299333, Training Accuracy= 0.88281\n",
      "Iter 51712, Minibatch Loss= 0.277703, Training Accuracy= 0.89844\n",
      "Iter 51840, Minibatch Loss= 0.223960, Training Accuracy= 0.92188\n",
      "Iter 53248, Minibatch Loss= 0.061449, Training Accuracy= 0.99219\n",
      "Iter 53376, Minibatch Loss= 0.145601, Training Accuracy= 0.93750\n",
      "Iter 53760, Minibatch Loss= 0.099986, Training Accuracy= 0.96875\n",
      "Iter 53888, Minibatch Loss= 0.174603, Training Accuracy= 0.95312\n",
      "Iter 55296, Minibatch Loss= 0.425920, Training Accuracy= 0.87500\n",
      "Iter 55424, Minibatch Loss= 0.159562, Training Accuracy= 0.93750\n",
      "Iter 55808, Minibatch Loss= 0.317071, Training Accuracy= 0.91406\n",
      "Iter 55936, Minibatch Loss= 0.352580, Training Accuracy= 0.93750\n",
      "Iter 57344, Minibatch Loss= 0.203143, Training Accuracy= 0.95312\n",
      "Iter 57472, Minibatch Loss= 0.227884, Training Accuracy= 0.92969\n",
      "Iter 57856, Minibatch Loss= 0.184583, Training Accuracy= 0.95312\n",
      "Iter 57984, Minibatch Loss= 0.353211, Training Accuracy= 0.89062\n",
      "Iter 59392, Minibatch Loss= 0.200985, Training Accuracy= 0.93750\n",
      "Iter 59520, Minibatch Loss= 0.316627, Training Accuracy= 0.90625\n",
      "Iter 59904, Minibatch Loss= 0.140592, Training Accuracy= 0.95312\n",
      "Iter 60032, Minibatch Loss= 0.139406, Training Accuracy= 0.95312\n",
      "Iter 61440, Minibatch Loss= 0.207106, Training Accuracy= 0.92188\n",
      "Iter 61568, Minibatch Loss= 0.215746, Training Accuracy= 0.93750\n",
      "Iter 61952, Minibatch Loss= 0.363423, Training Accuracy= 0.91406\n",
      "Iter 62080, Minibatch Loss= 0.199919, Training Accuracy= 0.92188\n",
      "Iter 63488, Minibatch Loss= 0.245035, Training Accuracy= 0.92188\n",
      "Iter 63616, Minibatch Loss= 0.279658, Training Accuracy= 0.93750\n",
      "Iter 64000, Minibatch Loss= 0.351405, Training Accuracy= 0.89062\n",
      "Iter 64128, Minibatch Loss= 0.450847, Training Accuracy= 0.89844\n",
      "Iter 65536, Minibatch Loss= 0.142673, Training Accuracy= 0.95312\n",
      "Iter 65664, Minibatch Loss= 0.239943, Training Accuracy= 0.92188\n",
      "Iter 66048, Minibatch Loss= 0.264115, Training Accuracy= 0.93750\n",
      "Iter 66176, Minibatch Loss= 0.271698, Training Accuracy= 0.90625\n",
      "Iter 67584, Minibatch Loss= 0.100864, Training Accuracy= 0.96875\n",
      "Iter 67712, Minibatch Loss= 0.161579, Training Accuracy= 0.96094\n",
      "Iter 68096, Minibatch Loss= 0.292112, Training Accuracy= 0.89844\n",
      "Iter 68224, Minibatch Loss= 0.271074, Training Accuracy= 0.91406\n",
      "Iter 69632, Minibatch Loss= 0.190243, Training Accuracy= 0.94531\n",
      "Iter 69760, Minibatch Loss= 0.208489, Training Accuracy= 0.93750\n",
      "Iter 70144, Minibatch Loss= 0.210928, Training Accuracy= 0.92969\n",
      "Iter 70272, Minibatch Loss= 0.179559, Training Accuracy= 0.95312\n",
      "Iter 71680, Minibatch Loss= 0.278856, Training Accuracy= 0.91406\n",
      "Iter 71808, Minibatch Loss= 0.215121, Training Accuracy= 0.90625\n",
      "Iter 72192, Minibatch Loss= 0.213311, Training Accuracy= 0.96094\n",
      "Iter 72320, Minibatch Loss= 0.233444, Training Accuracy= 0.91406\n",
      "Iter 73728, Minibatch Loss= 0.267372, Training Accuracy= 0.91406\n",
      "Iter 73856, Minibatch Loss= 0.318507, Training Accuracy= 0.92188\n",
      "Iter 74240, Minibatch Loss= 0.211014, Training Accuracy= 0.94531\n",
      "Iter 74368, Minibatch Loss= 0.190930, Training Accuracy= 0.96875\n",
      "Iter 75776, Minibatch Loss= 0.100859, Training Accuracy= 0.96875\n",
      "Iter 75904, Minibatch Loss= 0.174169, Training Accuracy= 0.94531\n",
      "Iter 76288, Minibatch Loss= 0.318505, Training Accuracy= 0.91406\n",
      "Iter 76416, Minibatch Loss= 0.116027, Training Accuracy= 0.95312\n",
      "Iter 77824, Minibatch Loss= 0.248019, Training Accuracy= 0.91406\n",
      "Iter 77952, Minibatch Loss= 0.170941, Training Accuracy= 0.94531\n",
      "Iter 78336, Minibatch Loss= 0.139704, Training Accuracy= 0.97656\n",
      "Iter 78464, Minibatch Loss= 0.189226, Training Accuracy= 0.95312\n",
      "Iter 79872, Minibatch Loss= 0.213412, Training Accuracy= 0.92969\n",
      "Iter 80000, Minibatch Loss= 0.342847, Training Accuracy= 0.89844\n",
      "Iter 80384, Minibatch Loss= 0.234464, Training Accuracy= 0.92188\n",
      "Iter 80512, Minibatch Loss= 0.204673, Training Accuracy= 0.94531\n",
      "Iter 81920, Minibatch Loss= 0.153184, Training Accuracy= 0.92188\n",
      "Iter 82048, Minibatch Loss= 0.191558, Training Accuracy= 0.92969\n",
      "Iter 82432, Minibatch Loss= 0.205529, Training Accuracy= 0.94531\n",
      "Iter 82560, Minibatch Loss= 0.098959, Training Accuracy= 0.97656\n",
      "Iter 83968, Minibatch Loss= 0.229478, Training Accuracy= 0.92188\n",
      "Iter 84096, Minibatch Loss= 0.133713, Training Accuracy= 0.92188\n",
      "Iter 84480, Minibatch Loss= 0.173076, Training Accuracy= 0.93750\n",
      "Iter 84608, Minibatch Loss= 0.108184, Training Accuracy= 0.95312\n",
      "Iter 86016, Minibatch Loss= 0.214848, Training Accuracy= 0.92969\n",
      "Iter 86144, Minibatch Loss= 0.139749, Training Accuracy= 0.95312\n",
      "Iter 86528, Minibatch Loss= 0.257871, Training Accuracy= 0.93750\n",
      "Iter 86656, Minibatch Loss= 0.325817, Training Accuracy= 0.89062\n",
      "Iter 88064, Minibatch Loss= 0.154841, Training Accuracy= 0.94531\n",
      "Iter 88192, Minibatch Loss= 0.384406, Training Accuracy= 0.92969\n",
      "Iter 88576, Minibatch Loss= 0.337004, Training Accuracy= 0.91406\n",
      "Iter 88704, Minibatch Loss= 0.156095, Training Accuracy= 0.95312\n",
      "Iter 90112, Minibatch Loss= 0.146472, Training Accuracy= 0.96875\n",
      "Iter 90240, Minibatch Loss= 0.246816, Training Accuracy= 0.92969\n",
      "Iter 90624, Minibatch Loss= 0.228309, Training Accuracy= 0.92969\n",
      "Iter 90752, Minibatch Loss= 0.223046, Training Accuracy= 0.92188\n",
      "Iter 92160, Minibatch Loss= 0.199080, Training Accuracy= 0.92969\n",
      "Iter 92288, Minibatch Loss= 0.097130, Training Accuracy= 0.95312\n",
      "Iter 92672, Minibatch Loss= 0.150788, Training Accuracy= 0.93750\n",
      "Iter 92800, Minibatch Loss= 0.211782, Training Accuracy= 0.92188\n",
      "Iter 94208, Minibatch Loss= 0.183400, Training Accuracy= 0.94531\n",
      "Iter 94336, Minibatch Loss= 0.186251, Training Accuracy= 0.96094\n",
      "Iter 94720, Minibatch Loss= 0.205884, Training Accuracy= 0.93750\n",
      "Iter 94848, Minibatch Loss= 0.190919, Training Accuracy= 0.94531\n",
      "Iter 96256, Minibatch Loss= 0.197510, Training Accuracy= 0.92969\n",
      "Iter 96384, Minibatch Loss= 0.267859, Training Accuracy= 0.91406\n",
      "Iter 96768, Minibatch Loss= 0.121699, Training Accuracy= 0.96094\n",
      "Iter 96896, Minibatch Loss= 0.145670, Training Accuracy= 0.95312\n",
      "Iter 98304, Minibatch Loss= 0.105941, Training Accuracy= 0.96875\n",
      "Iter 98432, Minibatch Loss= 0.257551, Training Accuracy= 0.91406\n",
      "Iter 98816, Minibatch Loss= 0.181493, Training Accuracy= 0.93750\n",
      "Iter 98944, Minibatch Loss= 0.222468, Training Accuracy= 0.92969\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.921875\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist_data\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "n_input = 28\n",
    "n_steps = 28\n",
    "n_hidden = 128\n",
    "n_classes = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "biases = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "x_trans = tf.transpose(x, [1, 0, 2])\n",
    "x_reshape = tf.reshape(x_trans, [-1, n_input])\n",
    "x_input = tf.split(0, n_steps, x_reshape)\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.BasicRNNCell( n_hidden)\n",
    "outputs, states = tf.nn.rnn(lstm_cell, x_input, dtype=tf.float32)\n",
    "pred = tf.matmul(outputs[-1], weights) + biases\n",
    "\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    step = 1\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        feed_dict = {x: batch_x, y: batch_y}\n",
    "        sess.run(optimizer, feed_dict)\n",
    "        if step & display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict)\n",
    "            loss = sess.run(cost, feed_dict)\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "Iter 128, Minibatch Loss= 2.683255, Training Accuracy= 0.12500\n",
      "Iter 512, Minibatch Loss= 2.171468, Training Accuracy= 0.21875\n",
      "Iter 640, Minibatch Loss= 2.291402, Training Accuracy= 0.25000\n",
      "Iter 2048, Minibatch Loss= 1.532178, Training Accuracy= 0.44531\n",
      "Iter 2176, Minibatch Loss= 1.663394, Training Accuracy= 0.46875\n",
      "Iter 2560, Minibatch Loss= 1.561150, Training Accuracy= 0.42188\n",
      "Iter 2688, Minibatch Loss= 1.486708, Training Accuracy= 0.50000\n",
      "Iter 4096, Minibatch Loss= 0.978530, Training Accuracy= 0.66406\n",
      "Iter 4224, Minibatch Loss= 0.994500, Training Accuracy= 0.65625\n",
      "Iter 4608, Minibatch Loss= 1.313783, Training Accuracy= 0.57031\n",
      "Iter 4736, Minibatch Loss= 0.920983, Training Accuracy= 0.68750\n",
      "Iter 6144, Minibatch Loss= 0.815255, Training Accuracy= 0.68750\n",
      "Iter 6272, Minibatch Loss= 0.906388, Training Accuracy= 0.66406\n",
      "Iter 6656, Minibatch Loss= 0.949728, Training Accuracy= 0.66406\n",
      "Iter 6784, Minibatch Loss= 0.925211, Training Accuracy= 0.67188\n",
      "Iter 8192, Minibatch Loss= 0.925509, Training Accuracy= 0.70312\n",
      "Iter 8320, Minibatch Loss= 0.643529, Training Accuracy= 0.81250\n",
      "Iter 8704, Minibatch Loss= 0.669011, Training Accuracy= 0.75781\n",
      "Iter 8832, Minibatch Loss= 0.716303, Training Accuracy= 0.79688\n",
      "Iter 10240, Minibatch Loss= 0.528877, Training Accuracy= 0.82031\n",
      "Iter 10368, Minibatch Loss= 0.444900, Training Accuracy= 0.85938\n",
      "Iter 10752, Minibatch Loss= 0.469229, Training Accuracy= 0.82812\n",
      "Iter 10880, Minibatch Loss= 0.580518, Training Accuracy= 0.80469\n",
      "Iter 12288, Minibatch Loss= 0.468666, Training Accuracy= 0.84375\n",
      "Iter 12416, Minibatch Loss= 0.390879, Training Accuracy= 0.86719\n",
      "Iter 12800, Minibatch Loss= 0.528126, Training Accuracy= 0.84375\n",
      "Iter 12928, Minibatch Loss= 0.620358, Training Accuracy= 0.79688\n",
      "Iter 14336, Minibatch Loss= 0.340636, Training Accuracy= 0.92969\n",
      "Iter 14464, Minibatch Loss= 0.287243, Training Accuracy= 0.89844\n",
      "Iter 14848, Minibatch Loss= 0.312771, Training Accuracy= 0.92188\n",
      "Iter 14976, Minibatch Loss= 0.286022, Training Accuracy= 0.92188\n",
      "Iter 16384, Minibatch Loss= 0.531947, Training Accuracy= 0.80469\n",
      "Iter 16512, Minibatch Loss= 0.253705, Training Accuracy= 0.91406\n",
      "Iter 16896, Minibatch Loss= 0.270598, Training Accuracy= 0.92188\n",
      "Iter 17024, Minibatch Loss= 0.300891, Training Accuracy= 0.94531\n",
      "Iter 18432, Minibatch Loss= 0.363997, Training Accuracy= 0.90625\n",
      "Iter 18560, Minibatch Loss= 0.278432, Training Accuracy= 0.92188\n",
      "Iter 18944, Minibatch Loss= 0.266921, Training Accuracy= 0.90625\n",
      "Iter 19072, Minibatch Loss= 0.444977, Training Accuracy= 0.89844\n",
      "Iter 20480, Minibatch Loss= 0.126833, Training Accuracy= 0.98438\n",
      "Iter 20608, Minibatch Loss= 0.320722, Training Accuracy= 0.90625\n",
      "Iter 20992, Minibatch Loss= 0.307494, Training Accuracy= 0.89844\n",
      "Iter 21120, Minibatch Loss= 0.173389, Training Accuracy= 0.94531\n",
      "Iter 22528, Minibatch Loss= 0.298772, Training Accuracy= 0.89062\n",
      "Iter 22656, Minibatch Loss= 0.207102, Training Accuracy= 0.91406\n",
      "Iter 23040, Minibatch Loss= 0.111687, Training Accuracy= 0.96875\n",
      "Iter 23168, Minibatch Loss= 0.211261, Training Accuracy= 0.92188\n",
      "Iter 24576, Minibatch Loss= 0.258309, Training Accuracy= 0.92969\n",
      "Iter 24704, Minibatch Loss= 0.329665, Training Accuracy= 0.89062\n",
      "Iter 25088, Minibatch Loss= 0.352659, Training Accuracy= 0.86719\n",
      "Iter 25216, Minibatch Loss= 0.374035, Training Accuracy= 0.86719\n",
      "Iter 26624, Minibatch Loss= 0.245211, Training Accuracy= 0.92188\n",
      "Iter 26752, Minibatch Loss= 0.434158, Training Accuracy= 0.84375\n",
      "Iter 27136, Minibatch Loss= 0.313742, Training Accuracy= 0.85938\n",
      "Iter 27264, Minibatch Loss= 0.209845, Training Accuracy= 0.93750\n",
      "Iter 28672, Minibatch Loss= 0.173492, Training Accuracy= 0.94531\n",
      "Iter 28800, Minibatch Loss= 0.204979, Training Accuracy= 0.93750\n",
      "Iter 29184, Minibatch Loss= 0.157948, Training Accuracy= 0.94531\n",
      "Iter 29312, Minibatch Loss= 0.158006, Training Accuracy= 0.95312\n",
      "Iter 30720, Minibatch Loss= 0.227443, Training Accuracy= 0.92969\n",
      "Iter 30848, Minibatch Loss= 0.130831, Training Accuracy= 0.96875\n",
      "Iter 31232, Minibatch Loss= 0.231410, Training Accuracy= 0.93750\n",
      "Iter 31360, Minibatch Loss= 0.083580, Training Accuracy= 0.96094\n",
      "Iter 32768, Minibatch Loss= 0.310282, Training Accuracy= 0.90625\n",
      "Iter 32896, Minibatch Loss= 0.213120, Training Accuracy= 0.94531\n",
      "Iter 33280, Minibatch Loss= 0.305968, Training Accuracy= 0.92188\n",
      "Iter 33408, Minibatch Loss= 0.327398, Training Accuracy= 0.85938\n",
      "Iter 34816, Minibatch Loss= 0.156505, Training Accuracy= 0.96875\n",
      "Iter 34944, Minibatch Loss= 0.385114, Training Accuracy= 0.89844\n",
      "Iter 35328, Minibatch Loss= 0.223366, Training Accuracy= 0.92188\n",
      "Iter 35456, Minibatch Loss= 0.142452, Training Accuracy= 0.96094\n",
      "Iter 36864, Minibatch Loss= 0.171088, Training Accuracy= 0.95312\n",
      "Iter 36992, Minibatch Loss= 0.184816, Training Accuracy= 0.94531\n",
      "Iter 37376, Minibatch Loss= 0.225364, Training Accuracy= 0.92969\n",
      "Iter 37504, Minibatch Loss= 0.290267, Training Accuracy= 0.92969\n",
      "Iter 38912, Minibatch Loss= 0.152260, Training Accuracy= 0.96875\n",
      "Iter 39040, Minibatch Loss= 0.172846, Training Accuracy= 0.93750\n",
      "Iter 39424, Minibatch Loss= 0.137685, Training Accuracy= 0.93750\n",
      "Iter 39552, Minibatch Loss= 0.218027, Training Accuracy= 0.94531\n",
      "Iter 40960, Minibatch Loss= 0.248266, Training Accuracy= 0.89844\n",
      "Iter 41088, Minibatch Loss= 0.218529, Training Accuracy= 0.92188\n",
      "Iter 41472, Minibatch Loss= 0.275146, Training Accuracy= 0.89844\n",
      "Iter 41600, Minibatch Loss= 0.112124, Training Accuracy= 0.96875\n",
      "Iter 43008, Minibatch Loss= 0.196045, Training Accuracy= 0.90625\n",
      "Iter 43136, Minibatch Loss= 0.140654, Training Accuracy= 0.96875\n",
      "Iter 43520, Minibatch Loss= 0.117933, Training Accuracy= 0.95312\n",
      "Iter 43648, Minibatch Loss= 0.219628, Training Accuracy= 0.93750\n",
      "Iter 45056, Minibatch Loss= 0.101738, Training Accuracy= 0.96875\n",
      "Iter 45184, Minibatch Loss= 0.164735, Training Accuracy= 0.94531\n",
      "Iter 45568, Minibatch Loss= 0.185323, Training Accuracy= 0.95312\n",
      "Iter 45696, Minibatch Loss= 0.234850, Training Accuracy= 0.96875\n",
      "Iter 47104, Minibatch Loss= 0.176553, Training Accuracy= 0.94531\n",
      "Iter 47232, Minibatch Loss= 0.308834, Training Accuracy= 0.89062\n",
      "Iter 47616, Minibatch Loss= 0.073229, Training Accuracy= 0.98438\n",
      "Iter 47744, Minibatch Loss= 0.203993, Training Accuracy= 0.93750\n",
      "Iter 49152, Minibatch Loss= 0.164259, Training Accuracy= 0.93750\n",
      "Iter 49280, Minibatch Loss= 0.122084, Training Accuracy= 0.95312\n",
      "Iter 49664, Minibatch Loss= 0.133537, Training Accuracy= 0.95312\n",
      "Iter 49792, Minibatch Loss= 0.094918, Training Accuracy= 0.96875\n",
      "Iter 51200, Minibatch Loss= 0.100516, Training Accuracy= 0.95312\n",
      "Iter 51328, Minibatch Loss= 0.176565, Training Accuracy= 0.95312\n",
      "Iter 51712, Minibatch Loss= 0.158496, Training Accuracy= 0.93750\n",
      "Iter 51840, Minibatch Loss= 0.117984, Training Accuracy= 0.96875\n",
      "Iter 53248, Minibatch Loss= 0.058960, Training Accuracy= 0.98438\n",
      "Iter 53376, Minibatch Loss= 0.033003, Training Accuracy= 0.99219\n",
      "Iter 53760, Minibatch Loss= 0.032519, Training Accuracy= 0.99219\n",
      "Iter 53888, Minibatch Loss= 0.100731, Training Accuracy= 0.96094\n",
      "Iter 55296, Minibatch Loss= 0.185395, Training Accuracy= 0.94531\n",
      "Iter 55424, Minibatch Loss= 0.137076, Training Accuracy= 0.96094\n",
      "Iter 55808, Minibatch Loss= 0.224794, Training Accuracy= 0.92969\n",
      "Iter 55936, Minibatch Loss= 0.183356, Training Accuracy= 0.94531\n",
      "Iter 57344, Minibatch Loss= 0.051667, Training Accuracy= 0.99219\n",
      "Iter 57472, Minibatch Loss= 0.146308, Training Accuracy= 0.94531\n",
      "Iter 57856, Minibatch Loss= 0.057387, Training Accuracy= 0.98438\n",
      "Iter 57984, Minibatch Loss= 0.127607, Training Accuracy= 0.94531\n",
      "Iter 59392, Minibatch Loss= 0.166576, Training Accuracy= 0.94531\n",
      "Iter 59520, Minibatch Loss= 0.080922, Training Accuracy= 0.97656\n",
      "Iter 59904, Minibatch Loss= 0.114661, Training Accuracy= 0.96094\n",
      "Iter 60032, Minibatch Loss= 0.084856, Training Accuracy= 0.97656\n",
      "Iter 61440, Minibatch Loss= 0.098662, Training Accuracy= 0.96875\n",
      "Iter 61568, Minibatch Loss= 0.192611, Training Accuracy= 0.92969\n",
      "Iter 61952, Minibatch Loss= 0.073301, Training Accuracy= 0.96875\n",
      "Iter 62080, Minibatch Loss= 0.188530, Training Accuracy= 0.92969\n",
      "Iter 63488, Minibatch Loss= 0.114766, Training Accuracy= 0.94531\n",
      "Iter 63616, Minibatch Loss= 0.079722, Training Accuracy= 0.98438\n",
      "Iter 64000, Minibatch Loss= 0.109706, Training Accuracy= 0.96094\n",
      "Iter 64128, Minibatch Loss= 0.081560, Training Accuracy= 0.98438\n",
      "Iter 65536, Minibatch Loss= 0.089872, Training Accuracy= 0.97656\n",
      "Iter 65664, Minibatch Loss= 0.082760, Training Accuracy= 0.98438\n",
      "Iter 66048, Minibatch Loss= 0.105249, Training Accuracy= 0.95312\n",
      "Iter 66176, Minibatch Loss= 0.058526, Training Accuracy= 0.98438\n",
      "Iter 67584, Minibatch Loss= 0.093699, Training Accuracy= 0.97656\n",
      "Iter 67712, Minibatch Loss= 0.065956, Training Accuracy= 0.97656\n",
      "Iter 68096, Minibatch Loss= 0.116842, Training Accuracy= 0.96094\n",
      "Iter 68224, Minibatch Loss= 0.164566, Training Accuracy= 0.94531\n",
      "Iter 69632, Minibatch Loss= 0.151707, Training Accuracy= 0.96094\n",
      "Iter 69760, Minibatch Loss= 0.040813, Training Accuracy= 0.99219\n",
      "Iter 70144, Minibatch Loss= 0.108607, Training Accuracy= 0.95312\n",
      "Iter 70272, Minibatch Loss= 0.174611, Training Accuracy= 0.95312\n",
      "Iter 71680, Minibatch Loss= 0.070250, Training Accuracy= 0.96875\n",
      "Iter 71808, Minibatch Loss= 0.113980, Training Accuracy= 0.96094\n",
      "Iter 72192, Minibatch Loss= 0.061359, Training Accuracy= 0.98438\n",
      "Iter 72320, Minibatch Loss= 0.092194, Training Accuracy= 0.96875\n",
      "Iter 73728, Minibatch Loss= 0.119107, Training Accuracy= 0.96875\n",
      "Iter 73856, Minibatch Loss= 0.108476, Training Accuracy= 0.97656\n",
      "Iter 74240, Minibatch Loss= 0.068693, Training Accuracy= 0.98438\n",
      "Iter 74368, Minibatch Loss= 0.057131, Training Accuracy= 0.98438\n",
      "Iter 75776, Minibatch Loss= 0.075278, Training Accuracy= 0.98438\n",
      "Iter 75904, Minibatch Loss= 0.105304, Training Accuracy= 0.98438\n",
      "Iter 76288, Minibatch Loss= 0.177964, Training Accuracy= 0.94531\n",
      "Iter 76416, Minibatch Loss= 0.101940, Training Accuracy= 0.98438\n",
      "Iter 77824, Minibatch Loss= 0.066827, Training Accuracy= 0.98438\n",
      "Iter 77952, Minibatch Loss= 0.043302, Training Accuracy= 0.99219\n",
      "Iter 78336, Minibatch Loss= 0.043818, Training Accuracy= 0.99219\n",
      "Iter 78464, Minibatch Loss= 0.078471, Training Accuracy= 0.97656\n",
      "Iter 79872, Minibatch Loss= 0.199822, Training Accuracy= 0.95312\n",
      "Iter 80000, Minibatch Loss= 0.077954, Training Accuracy= 0.96094\n",
      "Iter 80384, Minibatch Loss= 0.038898, Training Accuracy= 0.99219\n",
      "Iter 80512, Minibatch Loss= 0.092807, Training Accuracy= 0.96875\n",
      "Iter 81920, Minibatch Loss= 0.086669, Training Accuracy= 0.97656\n",
      "Iter 82048, Minibatch Loss= 0.134185, Training Accuracy= 0.97656\n",
      "Iter 82432, Minibatch Loss= 0.193858, Training Accuracy= 0.92969\n",
      "Iter 82560, Minibatch Loss= 0.037332, Training Accuracy= 1.00000\n",
      "Iter 83968, Minibatch Loss= 0.097389, Training Accuracy= 0.96875\n",
      "Iter 84096, Minibatch Loss= 0.144108, Training Accuracy= 0.95312\n",
      "Iter 84480, Minibatch Loss= 0.160436, Training Accuracy= 0.94531\n",
      "Iter 84608, Minibatch Loss= 0.093089, Training Accuracy= 0.97656\n",
      "Iter 86016, Minibatch Loss= 0.131526, Training Accuracy= 0.95312\n",
      "Iter 86144, Minibatch Loss= 0.119865, Training Accuracy= 0.95312\n",
      "Iter 86528, Minibatch Loss= 0.056031, Training Accuracy= 0.98438\n",
      "Iter 86656, Minibatch Loss= 0.137672, Training Accuracy= 0.96875\n",
      "Iter 88064, Minibatch Loss= 0.156178, Training Accuracy= 0.96094\n",
      "Iter 88192, Minibatch Loss= 0.138299, Training Accuracy= 0.95312\n",
      "Iter 88576, Minibatch Loss= 0.159336, Training Accuracy= 0.93750\n",
      "Iter 88704, Minibatch Loss= 0.146584, Training Accuracy= 0.93750\n",
      "Iter 90112, Minibatch Loss= 0.064484, Training Accuracy= 0.97656\n",
      "Iter 90240, Minibatch Loss= 0.147101, Training Accuracy= 0.95312\n",
      "Iter 90624, Minibatch Loss= 0.207454, Training Accuracy= 0.92188\n",
      "Iter 90752, Minibatch Loss= 0.101803, Training Accuracy= 0.96875\n",
      "Iter 92160, Minibatch Loss= 0.068962, Training Accuracy= 0.97656\n",
      "Iter 92288, Minibatch Loss= 0.057406, Training Accuracy= 0.99219\n",
      "Iter 92672, Minibatch Loss= 0.059623, Training Accuracy= 0.98438\n",
      "Iter 92800, Minibatch Loss= 0.105907, Training Accuracy= 0.96094\n",
      "Iter 94208, Minibatch Loss= 0.047185, Training Accuracy= 0.98438\n",
      "Iter 94336, Minibatch Loss= 0.074736, Training Accuracy= 0.96875\n",
      "Iter 94720, Minibatch Loss= 0.063640, Training Accuracy= 0.96875\n",
      "Iter 94848, Minibatch Loss= 0.064600, Training Accuracy= 0.98438\n",
      "Iter 96256, Minibatch Loss= 0.065757, Training Accuracy= 0.96875\n",
      "Iter 96384, Minibatch Loss= 0.104069, Training Accuracy= 0.93750\n",
      "Iter 96768, Minibatch Loss= 0.080487, Training Accuracy= 0.97656\n",
      "Iter 96896, Minibatch Loss= 0.055006, Training Accuracy= 0.98438\n",
      "Iter 98304, Minibatch Loss= 0.081506, Training Accuracy= 0.98438\n",
      "Iter 98432, Minibatch Loss= 0.050077, Training Accuracy= 0.97656\n",
      "Iter 98816, Minibatch Loss= 0.042466, Training Accuracy= 0.99219\n",
      "Iter 98944, Minibatch Loss= 0.097070, Training Accuracy= 0.96875\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.992188\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./mnist_data\", one_hot=True)\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 100000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "n_input = 28\n",
    "n_steps = 28\n",
    "n_hidden = 128\n",
    "n_classes = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_steps, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "biases = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "x_trans = tf.transpose(x, [1, 0, 2])\n",
    "x_reshape = tf.reshape(x_trans, [-1, n_input])\n",
    "x_input = tf.split(0, n_steps, x_reshape)\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell( n_hidden, forget_bias=1.0)\n",
    "outputs, states = tf.nn.rnn(lstm_cell, x_input, dtype=tf.float32)\n",
    "pred = tf.matmul(outputs[-1], weights) + biases\n",
    "\n",
    "cost = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    step = 1\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "        feed_dict = {x: batch_x, y: batch_y}\n",
    "        sess.run(optimizer, feed_dict)\n",
    "        if step & display_step == 0:\n",
    "            acc = sess.run(accuracy, feed_dict)\n",
    "            loss = sess.run(cost, feed_dict)\n",
    "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    test_len = 128\n",
    "    test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "    test_label = mnist.test.labels[:test_len]\n",
    "\n",
    "    print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
