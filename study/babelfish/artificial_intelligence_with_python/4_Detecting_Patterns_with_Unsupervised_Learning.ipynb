{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Detecting Patterns with Unsupervised Learning\n",
    "\n",
    "## 2017. 10. 19. YeongGeun Na\n",
    "\n",
    "1. What is **unsupervised learning**?\n",
    "2. Clustering data with **K-Means algorithm**\n",
    "3. Estimating the number of clusters with **Mean Shift algorithm**\n",
    "4. Estimating the quality of clustering with **silhouette scores**\n",
    "5. What are **Gaussian Mixture Models**?\n",
    "6. Building a classifier based on **Gaussian Mixture Models**\n",
    "7. Finding subgroups in stock market using **Affinity Propagation model**\n",
    "8. Segmenting the market based on shopping patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is unsupervised learning?\n",
    "\n",
    "Unsupervised learning은 label된 training data를 이용하지 않고 Maching learning model을 구축하는 과정을 의미합니다.\n",
    "\n",
    "- *market Segmentation, stock market, NLP, computer vision 등* 다양한 분야에서 사용됨\n",
    "- 실세계에서는, 데이터가 항상 label되어 있지 않고, 이 데이터를 어떤 방식으로든 분류만 해야하는 경우들이 있습니다. \n",
    "\n",
    "Unsupervised Learning algorithm은 몇몇 similarity metric을 사용하여 주어진 dataset 안에서 subgroup을 찾을 수 있는 모델을 구축합니다.\n",
    "\n",
    "이 chapter에서는 unsupervised learning에서 이런 문제들을 어떻게 공식으로 풀어나가는지 설명합니다.\n",
    "\n",
    "- label이 없는 dataset을 가지고 있을 때, 우리는 이 데이터가 latent variable(잠재변수)들이 영향을 미쳐 생성되었다고 가정합니다.\n",
    "- learning 과정은 개별 데이터 지점에서부터 시작하여 계층적 방법으로 진행될 수 있습니다.\n",
    "- 이를 통해, 우리는 데이터로 더 깊은 레벨의 표현 끌어낼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering data with K-Means algorithm\n",
    "\n",
    "Clusterring은 data들을 분석하여 그 안에 있는 cluster를 찾는 기술이다.\n",
    "\n",
    "- 데이터를 서로 비슷한 element들로 이루어진 subgroup으로 분류하는 과정이라고 할 수 있습니다.\n",
    "- unsupervised learning 기술 중 가장 많이 사용된다.\n",
    "\n",
    "cluster들을 찾기 위해, *Euclidean distance*와 같은 similarity measure가 사용된다.\n",
    "\n",
    "- 이런 similarity measure를 사용하여 cluster의 tightness를 평가할 수 있다.\n",
    "\n",
    "우리의 목표는 data point들을 같은 subgroup으로 속하게 만드는 intrinsic property를 식별하는 것입니다.\n",
    "\n",
    "- 모든 case에 동작하는 보편적 similarity metric은 없습니다.\n",
    "- 동작하는 similarity metric은 현재의 문제에 따라 다릅니다.\n",
    "  - 예를 들어, 대표 data point를 찾는 문제와, data들 속에서 이상한 값을 찾는 것은 다른 metric을 사용해야 할 것입니다.\n",
    "- 즉 상황에 맞는 적절한 metric을 선택해야 합니다.\n",
    "\n",
    "K-Means 알고리즘은 data를 clustering를 할 때 자주 사용됩니다.\n",
    "\n",
    "- 이 알고리즘을 사용하기 위해서는 cluster의 개수를 미리 알고 있어야 합니다.\n",
    "- 다양한 data attribute를 사용하여, data를 K개의 subgroup에 분류합니다.\n",
    "- 각 반복마다 우리는 K centroid의 위치를 업데이트 합니다.\n",
    "  - K centroid는 subgroup의 중심 위치입니다.\n",
    "  - 이것이 핵심 아이디어 입니다.\n",
    "- 이 과정을 centroid가 optimal한 위치에 갈 때까지 반복합니다.\n",
    "\n",
    "![https://image.slidesharecdn.com/k-mean-clustering-150729122635-lva1-app6892/95/k-meanclustering-algorithm-9-638.jpg?cb=1438172869](https://image.slidesharecdn.com/k-mean-clustering-150729122635-lva1-app6892/95/k-meanclustering-algorithm-9-638.jpg?cb=1438172869)\n",
    "\n",
    "위에서 알 수 있듯 centroid의 초기 위치는 이 알고리즘에서 중요합니다.\n",
    "\n",
    "- 이 초기 위치는 결과에 영향을 미치기에, 똑똑한 방법을 거쳐 정해야 합니다.\n",
    "- 좋은 전략으로, centroid를 서로 최대한 멀리 위치시키는 방법이 있습니다.\n",
    "- 하지만 outlier가 선택되는 경우가 있을 수 있습니다.\n",
    "\n",
    "![http://cfile5.uf.tistory.com/image/1456BF0C49F324A5E8974A](http://cfile5.uf.tistory.com/image/1456BF0C49F324A5E8974A)\n",
    "\n",
    "\n",
    "![http://cfile25.uf.tistory.com/image/197BDD0B49F32746CEDBE2](http://cfile25.uf.tistory.com/image/197BDD0B49F32746CEDBE2)\n",
    "\n",
    "기본적인 K-Means 알고리즘은 K-Means++를 이용해 초기 위치를 도출합니다.\n",
    "\n",
    "\n",
    "1. 1 번째 center는 랜덤으로 정한다.\n",
    "2. for i = 2 ~ k\n",
    "  - 모든 인스턴스 x마다 아래의 확률을 부여한다.\n",
    "    - p(x) = D(x)2/Σx'D(x')2     [x'는 인스턴스집합 X의 원소들]\n",
    "    - 여기서 D(x)는 x에서 지금까지의 center중 제일 가까운 center와의 거리를 뜻한다.\n",
    "  - 그러면, 모든 인스턴스에 확률이 부여된 이 상태에서 i 번째 center를 'random으로 찍는다'.\n",
    "    - 높은 확률이 부여되어 있다는 것은 i번째 center로 선정될 가능성이 높다는 뜻이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9ffa39e1ed97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/notebook/lib/python3.6/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0m__check_build\u001b[0m  \u001b[0;31m# avoid flakes unused variable error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/notebook/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_clustering.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a1c46639d1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 입력 데이터를 가져온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_clustering.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/envs/notebook/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_clustering.txt'"
     ]
    }
   ],
   "source": [
    "# 입력 데이터를 가져온다.\n",
    "X = np.loadtxt('data_clustering.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means 알고리즘을 적용하기 전에 먼저 cluster의 개수를 정한다.\n",
    "num_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 데이터의 분포를 쉽게 볼 수 있도록 그래프로 표현한다\n",
    "# 이 코드는 그래프를 그리기 위한 코드\n",
    "plt.figure()\n",
    "plt.scatter(X[:,0], X[:,1], marker='o', facecolors='none', edgecolors='black', s=80)\n",
    "x_min, x_max = X[:, 0].min() -1, X[:, 0].max() + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
