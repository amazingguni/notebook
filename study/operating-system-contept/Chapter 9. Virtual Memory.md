# 9.1 배경

그동안 봤던 메모리 관리 알고리즘들은 전체 프로세스를 메모리에 올려서 현재 실행되고 있는 코드는 반드시 물리 메모리에 존재해야 한다는 요구 조건을 만족시켰다.

- 동적 적재로 전체 프로세스를 메모리에 올리는 제약은 일부 완화했다.
- 실제로 프로그램 전체가 항상 메모리에 올라와 있어야 하지는 않는다.
	- 오류 코드는 실제 사용하는 경우가 적다
	- 할당받은 심벌이나, 메모리를 사용하지 않는 경우도 있다.
	- 프로그램 내의 옵션 중 거의 쓰지 않는 옵션도 있다.

프로그램의 일부만 메모리에 올려놓고 실행할 수 있다면 아래 이점을 갖는다.

1. 프로그램은 물리 메모리에 의해 제약받지 않게 된다.
	- 매우 큰 가상 주소 공간을 가정하고 프로그램을 만들 수 있다.
2. 각 사용자 프로그램이 더 작은 메모리를 차지하므로 더 많은 프로그램을 동시에 실행할 수 있게 된다.
	- 응답시간은 늘어나지 않으면서 CPU 이용률, 처리율은 높아진다.
3. 프로그램을 메모리에 올리고 스왑하는데 필요한 입출력 횟수가 줄어든다
	- 프로그램들이 보다 빨리 실행될 수 있다.

가상 메모리는 실제의 물리 메모리 개념과 사용자의 논리 메모리 개념을 분리한 것이다.

- 작은 메모리를 가지고도 얼마든지 큰 가상 주소 공간을 제공할 수 있어진다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_01_VirtualMemoryLarger.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_01_VirtualMemoryLarger.jpg)

가상 주소 공간은 프로세스가 메모리에 저장되는 논리적인 모습을 말한다.

- 0부터 연속적인 공간
- 논리적인 페이지를 물리적인 페이지 프레임으로 사상하는 것은 MMU가 할 일이다.
- 힙은 동적 할당 메모리를 사용함에 따라 주소 공간에서 위쪽으로 확장된다.
- 스택은 함수 호출을 거듭함에 따라 아래쪽으로 확장된다.
- 힙과 스택 사이의 공백도 가상 주소 공간의 일부이지만 확장되야만 물리 페이지를 요구할 것이다.
- 공백을 포함하는 가상 주소 공간을 sparse 주소 공간이라고 한다.
- 이 공간은 힙, 스택, 동적 라이브러리 링크 시에 사용된다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_02_VirtualAddressSpace.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_02_VirtualAddressSpace.jpg)

가상 메모리는 페이지 공유를 통해 파일이나 메모리가 둘 이상의 프로세스들에 의해 공유되는 것을 가능하게 한다.

1. 시스템 라이브러리가 여러 프로세스들 사이에 공유될 수 있다.
	- 각 프로세스들은 공유 라이브러리가 자신의 가상 주소 공간의 일부라고 생각하지만, 실제로는 해당 물리 메모리 페이지는 모든 프로세스에게 공유되고 있다.
2. 가상 메모리는 프로세스들이 메모리를 공유하는 것을 가능하게 한다.
3. fork 시스템 콜을 통한 프로세스 생성 과정에서 페이지들이 공유되는 것을 가능하게 한다. 이로 인해 빠르게 프로세스가 생성되게 된다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_03_SharedLibrary.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_03_SharedLibrary.jpg)

# 9.2 요구 페이징(Demand Paging)

초기에 필요한 것들만 메모리에 적재하는 기법을 요구 페이징이라고 한다. 요구 페이징을 사용하는 가상 메모리에서는 페이지들이 실행 과정에서 실제로 필요해질 때 적재된다.

- 즉 한 번도 접근되지 않는 페이지는 물리 메모리에 적재되지 않는다.
- 가상 메모리는 대개 요구 페이징 방식으로 구현되며, 세그먼테이션 시스템이더라도 하나의 세그먼테이션이 여러 페이지로 나뉘는 페이지된 세그먼테이션 기법을 사용한다.

요구 페이징 기법은 스와핑 기법과 비슷하다.

1. 프로세스는 보조메모리에 존재한다.
2. 프로세스를 실행하고 싶으면 메모리로 읽어 들이는데 이때 전체 프로세스를 읽어오지 않고 게으른 페이저를 사용한다.
	- 이 게으른 페이저는 그 페이지가 필요하지 않는 한 메모리에 적재하지 않는다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_04_PagedMemoryTransfer.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_04_PagedMemoryTransfer.jpg)

## 9.2.1 기본 개념

페이저는 프로세스를 스왑인 할 때에 실제 필요한 메모리들만 메모리로 읽어온다.

- 시간/메모리 낭비 줄임

이렇게 하려면 어느 페이지가 디스크에 있고, 메모리에 올라와 있는지 구별할 수 있어야 한다.

- 여기서 유효 무효 비트(valid-invalid) 가 사용될 수 있다.
- valid면 메모리에 있고 invalid면 유효하지 않거나 디스크에 존재한다는 것을 의미

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_05_PageTable.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_05_PageTable.jpg)

프로세스가 메모리에 올라와 있지 않은 페이지에 접근하려고 하면, 페이징 하드웨어는 항목이 invalid로 설정되어 있으므로 운영체제에 페이지 부재 트랩을 발생시킨다.

페이지 부재를 처리하는 과정은 다음과 같다.

1. 프로세스에 대한 내부 테이블(PCB내 유지)을 검사해서 메모리 참조가 유효/무효 인지를 알아낸다.
2. 무효한 페이지에 대한 참조라면 프로세스는 중단된다.
3. 유효한 참조인데 페이지가 아직 메모리에 올라와있지 않다면.
	1. 빈 공간(자유 프레임)을 찾는다
		- 페이지 프레임 리스트에서 하나를 가져온다
	2. 디스크에 새로이 할당된 프레임으로 해당 페이지를 읽어 들이도록 요청한다.
	3. 디스크 일기가 끝나면 이 페이지가 메모리에 있다는 것을 알리기 위해 페이지 테이블을 갱신하며, 프로세스가 유지하고 있는 내부 테이블을 수정한다.
	4. 트랩에 의해 중단되었던 명령어를 다시 실행한다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_06_PageFaultSteps.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_06_PageFaultSteps.jpg)

어떤 페이지가 필요해지기 전에는 결코 그 페이지를 메모리로 적재하지 않는 방법을 순수 요구 페이징이라고 한다.

참조 지역성이라는 성질이 있어서 프로그램의 어느 한 특정 작은 부분만 한동안 집중적으로 참조하는데 이러한 성질 덕분에 요구 페이징은 만족할 만한 성능을 보여준다.

요구 페이징을 지원하기 위해 필요한 하드웨어는 페이징과 스와핑을 위한 하드웨어와 동일한다.

1. 페이지 테이블
	- 유효무효 비트 또는 보호 비트의 특수한 값을 이용해 항목을 무효로 설정할 수 있어어ㅑ 함
2. 보조 기억장치
	- 주 메모리에 없는 모든 페이지를 가지고 있다.
	- 보통은 고속의 디스크이며, 스왑 장치라고도 한다.
	- 이 목적을 위해 할당되는 디스크 영역을 스왑 공간이라 한다.

또 요구 페이징을 위해서는 페이지 부재 오류 처리 후에 명령어를 다시 시작할 수 있어야 한다는 것이다.

- 연산 중간에 페이징이 발생하면 복귀 이후 연산을 다시 실행해야 한다.

페이징은 CPU와 메모리 사이에 들어간다.

- 사용자 프로세스는 페이징의 존재를 몰라야 한다.

## 9.2.2 요구 페이징의 성능

요구 페이징의 성능은 페이지 부재율이 좌우한다.

페이지 부재율이 높으면 유효 접근 시간도 높아진다.

스왑 공간에서의 디스크 입출력은 일반적으로 파일 시스템에서의 입출력보다 빠르다.

- 스왑 공간은 더 큰 블록을 사용하고, 파일 탐색이나 간접 할당 방법 등을 사용하지 않기 때문
- 시스템은 프로세스를 시작시킬 때 파일 이미지 전체를 스왑 공간으로 복사한 후 스왑 공간으로부터 요구 페이징을 처리함으로써 페이징 처리율을 높힐 수 있다.

# 9.3 Copy-on-write

보통 fork 이후 exec 를 호출하기 때문에 페이지들을 복사할 필요가 없다.

- 이 때 공유되는 페이지를 Copy-on-write 페이지라고 표시한다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_07_Page_C_Unmodified.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_07_Page_C_Unmodified.jpg)

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_08_Page_C_Modified.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_08_Page_C_Modified.jpg)

운영체제는 페이지 요청 시 할당하기 위해 빈 페이지 집합을 유지하고 있다.

- 빈 페이지가 프로세스에게 할당되는 경우는 Copy-on-write를 할 때, 혹은 스택이나 힙 공간을 확장해야 할 때이다.
- 운영체제는 페이지를 할당할 그 때에 0으로 채워서 할당한다.(이전까지는 이전 내용이 남아 있다)

> vfork는 부모와 자식이 페이지를 공유하지 않는다. 호출 이후 부모는 잠시 멈추고, 자식이 부모의 페이지를 가지고 실행되게 된다. 바로 exec을 하는 경우에는 매우 효율적인 방법이다.

# 9.4 페이지 교체

요구 페이지를 통해 다중 프로그래밍 정도를 올릴 수 있는데, 과하게 올렸을 경우 메모리 과할당이 발생할 수 있다.

40프레임이 있었을 때 10개의 페이지 중 5개만을 사용하는 6개의 프로세스를 실행시키면, 

- 10개의 프레임을 남겨 놓고도 높은 CPU 활용률과 처리율을 얻을 수 있다.
- 하지만 프로세스들이 10개의 페이지를 모두 사용해진다면, 60 프레임을 필요로 하게 된다.

과할당은 아래와 같이 발견된다.

1. 페이지 부재가 발생하고
2. 운영체제가 필요한 페이지가 디스크의 어디에 위치하고 있는지 알아내던 중
3. 빈 프레임이 없음을, 즉 모든 메모리가 사용 중임을 발견한다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_09_PageNeed.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_09_PageNeed.jpg)

과할당이 발견되면 운영체제는 몇 가지 선택을 할 수 있다.

1. 프로세스 종료 -> 나쁜 선택
2. 운영체제는 이 경우 프로세스 하나를 스왑 아웃하여 그 프로세스의 프레임을 해제한다.
3. 페이지 교체 -> 다음 장부터 이를 살펴본다.

## 9.4.1 기본적인 페이지 교체

1. 디스크에서 필요한 페이지의 위치를 알아낸다.
2. 빈 페이지 프레임을 찾는다
	1. 빈 프레임이 있다면 그것을 사용한다.
	2. 없다면 희생될 프레임을 선정하기 위하여 페이지 교체 알고리즘을 가동시킨다.
	3. 희생될 페이지를 디스크에 기록하고, 관련 테이블을 수정한다
3. 새롭게 비워진 프레임에 새 페이지를 읽어오고 프레임 테이블을 수정한다.
4. 사용자 프로세스를 재시작한다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_10_PageReplacement.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_10_PageReplacement.jpg)

빈 프레임이 없는 경우에는 디스크를 두 번(프레임을 비울때, 읽어들일 때) 접근해야 한다.

이러한 오버헤드를 줄이기 위해 변경 비트가 페이지 테이블에 필요하다.

- 변경 비트는 CPU가 페이지 내의 어떤 워드나 바이트라도 쓰게 되면 설정된다.
- 희생시킬 페이지가 선정되면 변경 비트를 확인하고 변경되었을 경우에만 디스크에 기록하게 된다.
- 이런 기법은 읽기 전용 페이지들에도 적용된다

요구 페이징 시스템은 두 가지 중요한 문제를 해결해야 한다.

1. 프레임 할당 알고리즘
2. 페이지 교체 알고리즘

페이지 교체 알고리즘은 페이지 부재율이 가장 낮은 것을 선정하게 된다.

- 특정 메모리 참조 나열에 대해 알고리즘을 적용하여 페이지 부재 발생 회수를 계산하여 평가한다.

가용 페이지 프레임 수가 증가하면 페이지 부재의 수는 떨어지게 된다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_11_PageFaultGraph.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_11_PageFaultGraph.jpg)

## 9.4.2 FIFO 페이지 교체

각 페이지마다 메모리에 적재된 시간을 기억하고 교체해야 할 때 가장 오래된 페이지를 내쫓는다.

- 페이지들이 올라온 순서대로 FIFO queue를 만들어 유지하고 있어도 된다.

프레임이 3개가 있다고 가정 했을 때, 15번의 페이지 폴트가 발생한다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_12_FIFO_PageReplacement.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_12_FIFO_PageReplacement.jpg)

FIFO는 이해하기 쉽고 프로그래밍도 쉽다.

- 성능이 항상 좋은 것은 아니다.
- 교체된 페이지가 자주 사용되는 페이지일 수도, 그렇지 않을 수도 있다

FIFO 교체 알고리즘에서는 페이지가 늘어나는데도 페이지 부재가 늘어나는 현상이 발생할 수 있다.

- 이를 Belady의 모순이라고 부른다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_13_PageFaultCurve.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_13_PageFaultCurve.jpg)

## 9.4.3 최적 페이지 교체

최적 교체 알고리즘은 가장 낮은 페이지 부재율을 보이며 Belady의 모순이 발생하지 않는다.

- 앞으로 가장 오랫동안 사용되지 않을 페이지를 찾아 교체한다.
- 하지만 이 알고리즘은 프로세스가 앞으로 메모리를 어떻게 참조할 것인지를 미리 알아야 하기 때문에 구현이 어렵다.
- 연구 목적으로 사용된다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_14_OptimalPageReplacement.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_14_OptimalPageReplacement.jpg)

## 9.4.4 LRU 페이지 교체(Least-Recently-Used)

최근의 과거를 가까운 미래의 근사치로 본다면 가장 오랜 기간 동안 사용되지 않은 페이지를 교체할 수 있다. 이 기법이 Least Recently-Used(LRU) 알고리즘이다.

- LRU 알고리즘은 각 페이지마다 마지막 사용 시간을 유지한다.
- 가장 오랫동안 사용되지 않은 페이지를 선택한다.

![	https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_15_LRU_PageReplacement.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_15_LRU_PageReplacement.jpg)

LRU는 자주 사용되며 좋은 알고리즘으로 인정받는다.

- 하드웨어의 지원 필요
- 프레임들을 최근 사용된 시간 순서로 파악할 수 있어야 한다.
	- counter: 각 프레임에 시간을 기록하는 방법이다. 
		- 간단하지만, 탐색해야 하고, 메모리 쓰기 쓰기가 필요하다는 단점이 있다. 
		- 시간 값이 오버 플로나는 경우도 고민이 필요하다.
	- stack: 페이지 번호의 스택을 유지하는 방법이다.
		- 페이지가 참조될 때마다 페이지 번호는 스택 중간에서 제거되어 꼭대기에 놓이게 된다.
		- 프레임 교체는 바닥에 있는 것으로 수행하게 된다.

LRU는 Belady의 모순 현상이 일어나지 않는다.

- 모순이 일어나지 않는 알고리즘을 스택 알고리즘이라고 한다.
- n개의 프레임에 적재되는 페이지의 집합이 항상 n+1개의 프레임에 적재되는 페이지 집합의 부분집합

## 9.4.5 LRU 근사 페이지 교체

LRU 페이지 교체를 지원할 수 있는 시스템이 거의 없기 때문에, 어떤 시스템에서는 하드웨어 지원 없이 다른 알고리즘을 쓸 수밖에 없다.

이런 경우 참조 비트를 참고하여 0인 페이지를 우선적으로 희생 프레임으로 삼음으로써 LRU 근사 페이지 교체를 수행한다.

### 9.4.5.1 부가적 참조 비트 알고리즘

일정한 주기로 참조 비트를 기록함으로써 선후 관계 정보를 기록한다.

- 참조 비트에 1을 상위 비트에 넣고, 일정 시간마다 오른쪽으로 쉬프트한다.
- 8비트를 참조 비트에 할당하게 된다.
- 최초로 참조되면 10000000  ->  01000000 -> 00100000 이 된다.
- 1100100인 페이지는 01110111인 페이지보다 더 최근에 사용되는 것이다.

### 9.4.5.2 2차 기회 알고리즘

2차 기회 알고리즘의 기본은 FIFO 교체 알고리즘이다.

그러나 페이지가 선택될 때마다 참조 비트를 확인한다.

1. 참조 비트가 0이면 페이지를 교체하고
2. 1이면 다시 한 번 기회를 주고 다음 FIFO 페이지를 선택하기 위해 이동한다.
	- 한 번 더 기회를 받게 되면 참조 비트는 해제되고 도착 시간이 현재 시간으로 재설정된다.

이렇게 하면,

- 2차 기회가 주어진 페이지는 다른 모든 페이지들이 교체되거나 기회를 받을 때까지 교체되지 않는다.
- 참조 비트가 계속 설정되어 있을 정도로 자주 사용되는 페이지는 교체되지 않을 것이다.

2차 기회 알고리즘을 구현하는 하나의 방법은 순환 큐를 이용하는 것이다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_17_SecondChance.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_17_SecondChance.jpg)

### 9.4.5.3 개선된 2차 기회 알고리즘

2차 기회 알고리즘은 참조 비트와 변경 비트를 순서쌍으로 생각하여 사용하면 등급을 더 늘릴 수 있다.

1. (0, 0): 최근에 사용되지도 변경되지도 않은 경우 -> 우선 교체 대상
2. (0, 1): 최근에 사용되지는 않았지만 변경은 된 경우 -> 디스크에 내용을 기록해야 하기 때문에 교체에 적당하지는 않음
3. (1, 0): 최근에 사용은 되었으나 변경은 되지 않음 -> 이 페이지는 곧 다시 사용될 가능성이 높음
4. (1, 1): 최근에 사용되었고 변경도 된 경우 -> 최후 교체 대상

## 9.4.6 계수 기반 페이지 교체(Counting-Based Page Replacement)

LFU(Lease Frequently Used) 알고리즘

- 참조 회수가 가장 적은 페이지를 교체하는 방법

MFC(Most Frequently Used) 알고리즘

- 참조 회수가 가장 많은 페이지를 교체하는 방법


둘다 잘 안쓰인다


## 9.4.7 페이지 버퍼링 알고리즘

1. 가용 프레임 풀을 운영하는 방법
2. 페이징 장치가 유휴 상태일 때마다 변경된 페이지들을 선택하여 디스크에 쓰고 변경 비트를 0으로 변경
	- 쓰기 상태를 해제해 쉽게 교체되게 만듬
3. 가용 프레임 풀을 운영하면서, 과거에 어떤 프레임이였는지를 기억
	- 만약 해당 프레임에서 다시 폴트가 발생하면 바로 할당


# 9.5 프레임의 할당

다양한 프로세스들에게 제한된 가용 메모리를 어떻게 할당할 것인가?

운영체제가 모든 버퍼나 테이블 공간을 가용 프레임 리스트에서 할당받도록 할 수 있다.

- 언제나 가용 프레임 리스트에 3개의 프레임은 예비로 남겨두고
- 페이지 폴트가 발생하면 페이지 스왑이 일어나는 동안 교체될 프레임을 풀에서 제공한다.
- 그리고 디스크에 쓰는 작업도 완료되게 된다.

기본적인 전략은 사용자 프로세스는 어떤 가용 프레임이든 할당받아야 한다는 것이다.

## 9.5.1 최소로 할당해야 할 프레임의 수

각 프로세스에 최소한 몇 페이지는 할당되어야 한다.

- 프레임 수가 줄어들면 페이지 부재율이 증가해 실행 속도가 느려진다.
- 프로세스는 하나의 명령어가 참조하는 모든 페이지를 적재할 수 있는 최소한의 프레임을 가지고 잇어야 한다.

프로세스 당 필요한 최소 프레임 수는 컴퓨터 구조에 의해 결정된다.

- 간접 참조 레벨이 이 수를 늘리는 역할을 하기 때문에 일반적으로 제약을 가한다.(예를 들어 16단계)

프로세스 당 최소 프레임 수는 구조에 의해 결정되고 최대 할당 수는 가용 물리 메모리에 의해 결정된다.

## 9.5.2 할당 알고리즘

프로세스들에게 균등하게 할당하는 방법이 가장 쉽다.

- 93개의 프레임과 5개의 프로세스가 있을 경우 18개씩 분배하고 3개는 가용 프레임 버퍼 풀로 사용

다른 대안은 프로세스 규모에 따라 비례 할당하는 것이다.

- 최소 할당 수보다는 큰 정수로 조정한다.

## 9.5.3 전역 대 지역 할당

일반적으로 전역 교체가 지역 교체보다 더 좋은 시스템 처리량을 보이며 널리 사용된다.

- 전역 교체에서는 프로세스가 교체할 프레임을 모든 프레임을 대상으로 찾는다
 	- 프로세스에 할당되는 프레임의 수가 바뀔 수 있다.
	- 한 프로세스가 페이지 부재율을 조절할 수가 없다.
	- 동일한 프로세스도 그때그때 속도가 달라질 수 있다.
- 지역 교체에서는 자신의 프로세스에 할당된 프레임들 중에서만 교체 대상을 찾는다
	- 프로세스에 할당되는 프레임의 수가 바뀌지 않는다

## 9.5.4 비균등 메모리 접근

특정 보드 상의 CPU는 같은 보드의 메모리를 다른 보드의 메모리보다 더 빠르게 접근할 수 있다.

메모리 접근 시간이 현저하게 차이가 나는 시스템을 모두 비균등 메모리 접근(non-uniform memory access, NUMA) 시스템이라 한다.

- 메모리 관리 시스템이 스케줄된 CPU와 가까운 프레임을 할당하면, 캐시 적중률이 높아지고 메모리 접근 시간도 줄어들 것이다.

solaris는 커널 내에 lgroup이라는 개체를 만들어 가까운 CPU와 메모리를 모아두었다.

- 스레드와 메모리 할당을 이 lgroup 단위로 처리하여 메모리 지연을 최소화한다.

# 9.6 쓰레싱(Thrashing)

화랍ㄹ하게 사용되는 페이지 집합을 지원해 줄 만큼 프레임을 충분히 할당받지 못한 프로세스는 페이지 부재가 바로 발생할 것이다. 이 때 페이지 교체가 필요하지만 이미 활발하게 사용되는 페이지들만으로 이루어져 잇으므로 어떤 페이지가 교체되든 바로 다시 필요해 질 것이다. 결과적으로 바로바로 계속해서 페이지 부재가 발생하고, 곧바로 읽어들여야 할 페이지를 연속적으로 교체하게 된다.

이런 과도한 페이징 작업을 쓰레싱이라고 부른다.

- 어떤 프로세스가 실행보다 더 많은 시간을 페이징에 사용하고 있을 경우 쓰레싱이 발생했다고 한다.

## 9.6.1 스레싱의 원인

운영체제는 CPU 이용률이 너무 낮아지면 새로운 프로세스를 시스템에 더 추가해 멀티 프로그래밍의 정도를 높힌다.

- 이 때 전역 페이지 교체 알고리즘을 사용한다.

한 프로세스가 새로운 실행 단계로 진입하여 더 많은 프레임을 필요로 한다고 가정하자

- 교체된 페이지들이 원래 프로세스에서 필요로 하는 것이었다면, 그 프로세스 역시 페이지 부재를 발생시키고 또 다른 프로세스에서 프레임을 가져온다.
- 이러한 프로세스들은 페이지 인, 스왑 아웃을 위해 페이징 장치를 이용해야 한다.
- 이 프로세스들이 페이징 장치의 큐로 진입하면서 준비 완료 큐는 비게 된다.
- 프로세스들이 페이징 장치를 기다리는 동안 CPU 이용률은 떨어진다.

CPU 스케줄러는 이용률이 떨어지는 것을 보고, 이를 높이기 위해 새로운 프로세스를 추가해 멀티 프로그래밍의 정도를 높인다.

- 새로 시작되는 프로세스는 또 실행 중인 프로세스들로부터 프레임을 가져오고자 하며 더 많은 페이지 부재를 발생시킨다.
- 결국 쓰레싱이 일어나게 되어 시스템의 처리율은 대단히 낮아지고 페이지 부재는 엄청나게 늘어난다.

그 결과 유효 메모리 접근 시간은 증가하고 프로세스들은 페이징하는 데 시간을 다 소비하게 되어 아무런 일도 할 수 없게 된다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_18_Thrashing.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_18_Thrashing.jpg)

쓰레싱이 일어나면 다중 프로그래밍 정도를 낮춰야만 한다.

지역 교체 알고리즘을 사용하더라도 한 프로세스 내에서 쓰레싱이 발생했을 때 페이징 장치가 바빠져 다른 프로세스에 영향을 미칠 수도 있다.

이를 해결하기 위해 지역성 모델을 정의할 수 있다.

- 지역성 모델은 프로세스는 실행해 가면서 지역에서 지역으로 이동한다고 말한다.
- 지역이란 활발하게 함께 참조되는 페이지들의 집합을 의미한다.
- 한 프로그램은 여러 지역으로 구성되어 있고 이 지역들은 겹칠 수 있다.
- 이 프로세스에 필요로 하는 지역성의 크기보다 적은 프레임을 할당하게 되면, 그 프로세스는 쓰레싱이 일어난다.

## 9.6.2 작업 집합 모델

작업 집합 모델은 지역성을 토대로 하고 있다.

- 한 프로세스가 최근 n번 참조한 페이지들의 집합을 작업 집합이라고 부른다.
- 이는 지역성의 근사값이 된다.

작업 집합의 정확도는 이 n의 선택에 따라 좌우된다.

- 너무 작으면 전체 지역을 포함하지 못하고 반대의 경우 과도하게 수용하게 된다.

운영체제는 각 프로세스의 작업 집합을 감시하면서 각 프로세스에 작업 집합 크기에 맞는 충분한 프레임을 할당한다.

- 이렇게 할당하고도 가용 프레임이 있다면 다른 프로세스를 시작시킬 수 있다.

작업 집합의 합이 총 가용 프레임의 수를 넘게 되면, 운영체제는 보류시킬 프로세스를 선택한다.

- 보류된 프로세스는 스왑 아웃되고 사용하던 프레임들은 다른 프로세스에 재할당된다.

작업 집합 전략은 가능한 최대의 다중 프로그래밍의 정도를 유지하면서도 쓰레싱을 방지한다.

- 따라서 CPU의 이용률도 최적화된다.
- 참조 비트를 사용하여 작업 집합 모델의 근사를 구할 수 있다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_20_WorkingSetModel.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_20_WorkingSetModel.jpg)

## 9.6.3 페이지 부재 빈도(Page-Fault Frequency, PFF)

작업 집합 모델은 작업 집합을 알고 있으면 선 페이징을 할 때에는 유용하지만 쓰래싱을 조절하는 방법으로는 적당하지 않다.

페이지 부재 빈도(Page-Fault Frequency) 방식은 보다 더 직접적으로 쓰래싱을 조절한다.

- 페이지 부재율의 상한과 하한을 정해, 상한을 넘으면 프레임을 더 할당하고 하한보다 낮아지면 프레임 수를 줄인다.
- 직접적으로 부재율을 측정하고 제어하여 쓰레싱을 방지할 수 있다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_21_PageFaultFrequency.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_21_PageFaultFrequency.jpg)

# 9.7 메모리 사상 파일

파일의 메모리 사상은 가상 주소 공간의 일부가 논리적으로 파일과 관련되게 하는 방식이다.

- 입출력 실행 시에 현저한 성능 향상을 제공한다.

## 9.7.1 기본 메커니즘

파일의 메모리 사상은 하나의 디스크 블록을 메모리의 한 페이지 또는 페이지들로 사상함으로써 이루어진다.

- 첫 번째 접근은 일반적인 요구 페이징 과정에 따라 페이지 부재를 발생 시킨다.
- 그 파일 중 페이지 크기만큼의 해당 부분이 파일 시스템으로부터 물리 페이지로 읽혀 들어오게 된다.
- 그 이후의 파일 읽기/쓰기는 다른 메모리 액세스처럼 처리된다.

이 방법은 시스템 콜을 하는 오버헤드를 유발시키지 않고 메모리를 통해 파일을 조작할 수 있기 대문에 파일 접근과 사용을 간단하게 한다.

- 메모리에서 파일 입출력이 실행되기 때문에 파일에 훨씬 빠르게 접근할 수 있다.

메모리에 사상된 파일에 대한 쓰기는 디스크에 즉시 반영되지 않을 수 있다.

- 시스템에 따라서는 운영체제가 주기적으로 메모리 페이지의 변경여부를 검사할 때 반영하기도 한다.
- 프로세스가 파일을 닫으면 모든 메모리 사상 데이터는 디스크에 쓰이고 가상 메모리에서 제거된다.

solaris에서는 nmap()으로 사상하고 이후 파일 관련 시스템 콜로 조작할 수 있도록 제공하고 있다.

여러 프로세스들은 같은 파일을 동시에 메모리 사상하여 데이터를 공유할 수 있다.

- 한 프로세스의 수정이 다른 프로세스에게 공유된다.
- Copy-on-write를 적용해 수정이 공유되지 않게 할 수도 있다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_23_MemoryMappedFiles.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_23_MemoryMappedFiles.jpg)


- UNIX, Linux에서는 메모리 사상이 mmap(), 공유 메모리는 shmget(), shmat() 으로 처리된다
- Windows에서는 공유 메모리를 메모리 사상 파일을 이용하여 구현한다.


## 9.7.3 메모리 사상 I/O

I/O 컨트롤러는 명령어와 전송할 데이터를 담기 위한 레지스터들을 포함하고 있다.

많은 컴퓨터 구조는 메모리 사상 I/O 기능을 제공하고 있다.

- 특정 메모리 영역이 장치 레지스터들을 사상할 수 있도록 남겨둔다.
- 이 주소에 대한 읽기/쓰기 작업은 장치 레지스터로의 데이터 전송으로 처리된다.
- 보통은 전송할 데이터를 쓰고 제어 레지스터의 한 비트를 설정해 준비되었음을 알려준다.
- 그러면 장치는 데이터를 가져가고, 레지스터의 비트를 끔으로써 전송이 가능하다를 것을 알려준다.
	- 이러한 제어 비트 값을 CPU가 폴링하면서 확인하면 Programmed I/O(PIO)라고 한다.
	- 인터럽트를 통해 받는 경우는 interrupt driven이라고 부른다

# 9.8 커널 메모리의 할당

커널 메모리는 보통 사용자 모드 프로세스에게 할당해 주기 위해 별도의 메모리 풀에서 할당받는다.

이렇게 하는 2가지 큰 이유는 다음과 같다.

1. 커널은 다양한 크기의 자료구조를 위해 메모리를 할당받는다.
	- 이 자료구조들은 페이지 크기보다 작은 크기를 갖기도 한다.
	- 커널은 메모리 사용을 절재해야 하며, 단편화에 의한 낭비를 최소화하고자 한다.
2. 가상 메모리 인터페이스를 통하지 않고 물리 메모리에 직접 접근하는 특정 하드웨어 장치는 물리적으로 연속적인 메모리를 필요로 하는 경우가 있다.

## 9.8.1 버디 시스템

버디 시스템은 물리적으로 연속된 페이지들로 이루어진 고정된 크기의 세그먼트로부터 메모리를 할당한다.

메모리는 이 세그먼트로부터 2의 거듭제곱 단위로 할당된다.

- 2의 거듭제곱 크기가 아닌 요구는 올림된다.

버디 시스템의 이점 중 하나는 병합이라는 과정을 통해 서로 인접한 버디들이 손쉡게 하나의 큰 세그먼트로 합쳐질 수 있다는 점이다.

단점은 내부 단편화를 가져온다는 것이다.

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_27_BuddySystem.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_27_BuddySystem.jpg)

## 9.8.2 슬랩 할당

- 슬랩은 하나 또는 그 이상의 연속된 페이지들로 구성된다.
- 캐시는 하나 혹은 그 이상의 슬랩들로 구성된다.

각 커널 자료 구조마다 하나의 캐시가 존재한다.

- 각 캐시는 커널 자료 구조의 인스턴스로 생성된 객체들로 채워져 있다.
- e.g., pid를 위한 캐시, 파일 객체를 위한 캐시, 세마포어를 위한 캐시 등

![https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_28_SlabAllocation.jpg](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter9/9_28_SlabAllocation.jpg)

슬랩 할당 알고리즘은 커널 객체를 저장하기 위해 캐시를 사용한다.

1. 캐시가 생성되면 초기에는 free라고 표시된 몇 개의 객체들이 캐시에 할당된다.
	- 캐시 내 객체의 수는 해당 슬랩의 크기에 좌우된다.
2. 커널은 자료 구조를 위한 객체가 필요하면 free 객체들 중 하나를 캐시로부터 할당해준다.
3. 할당된 객체는 used라고 표시된다.

리눅스에서 슬랩은 다음과 같은 세 가지 상태 중 한 상태에 있게 된다.

1. Full
2. Empty
3. Partial

1. 슬랩 할당기는 먼저 Partial 슬립의 free 객체를 이용해 요청을 처리하려고 시도한다.
2. Partial 슬랩이 없으면 Empty 슬랩으로부터 free 객체를 할당한다.
3. Empty 슬랩도 없는 경우에는 새로운 슬랩이 연속된 물리 메모리에서 할당되어 캐시에 주어진다
4. 객체는 이 슬랩에서 할당된다.

슬랩 할당기는 두 가지 주요 장점이 있다.

1. 단편화에 의해 낭비되는 메모리가 없다.
2. 메모리 요청이 빠르게 처리된다.
	- 객체 할당/해제가 빈번한 경우 메모리를 관리하는데 효율적이다(커널 요청은 대부분 이런 특징)
	- 객체들이 미리 생성되어 있고, 쉽게 할당이 가능

Linux는 원래 버디 시스템이였으나 지금은 슬랩 할당기를 쓴다.


# 9.9 기타 고려 사항

## 9.9.1 프리페이징

프리페이징은 과도한 초기 페이징을 방지하기 위한 기법으로 필요하게 될 모든 페이지를 한꺼번에 메모리로 가져오는 기법이다.

작업 집합을 사용하는 시스템에서는 각 프로세스마다 작업 집합에 속한 페이지 리스트를 가지고 있다.

1. 어떤 프로세스를 보류시켜야 한다면 그 프로세스의 작업 집합을 기억해 놓는다.
2. 프로세스가 실행을 재개할 때에 작업 집합을 모두 메모리에 올려 놓고 시작한다.

프리페이징은 페이지 부재를 처리하는 비용보다 적은지를 비교하여 적용 여부를 결정해야 한다.

## 9.9.2 페이지 크기

내부 단편화나 지역성 같은 요소를 생각하면 작은 페이지가, 페이지 테이블 크기나 입출력 시간을 생각하면 페이지 크기가 큰 것이 좋다.

점점 커져가는 추세.

## 9.9.3 TLB 범위

TLB(Translation Lookaside Buffer) 적중률은 전체 가상 메모리 참조 중 페이지 테이블을 접근하지 않더라도, TLB 상에서 주소 변환을 실행할 수 있는 경우의 비율을 말한다.

- TLB의 항목수가 늘어나면 적중률이 늘어나지만 가격과 전력 소모도 늘어나게 된다.

TLB 범위는 TLB로부터 액세스할 수 있는 메모리의 양을 뜻한다.

- 이 값은 TLB 항목 * 페이지 크기 로 구한다.
- 이상적으로는 한 프로세스의 작업 집합이 TLB에 다 들어올 수 있어야 가장 좋다.
- 이 범위를 키우는 방법은 페이지 크기를 키우거나 여러 페이지 크기를 허용하는 것이다

여러 크기의 페이지를 지원하기 위해서는 운영체제가 TLB를 관리해야 한다.


- 이를 통해 TLB 내의 한 필드로 페이지 프레임의 크기를 나타낼 수 있다.
- 하드웨어가 아닌 소프트웨어가 관리함으로써 성능이 떨어질 수 있지만, 적중률과 TLB 범위의 향상으로 상쇄될 수 있다.
- 최근에는 이렇게 가는 추세

## 9.9.4 역 페이지 테이블

역페이지 테이블은 각 페이지 프레임에 어떤 가상 메모리 페이지가 저장되어 있는지에 대한 정보를 가지고 있다.

- 결과적으로 필요한 물리 메모리 양을 줄인다.

하지만 요구 페이징은 역 페이지 테이블을 일일히 조회할 수는 없기 때문에, 프로세스 당 하나씩 외부 페이지 테이블을 유지해야 한다.

- 다만, 외부 테이블은 하드웨어 적 지원이 없다. 페이지 부재 시에만 참조되기 때문에 속도가 매우 빠를 필요는 없다.
- 외부 테이블을 사용하더라도 역 페이지 테이블은 유용하다.
- 또한 외부 테이블은 그 자체가 페이징될 수도 있다. 

## 9.9.6 입출력 상호 잠금(I/O interlock)

어던 프로세스가 입출력 요구를 하고 입출력 장치의 큐에 들어갔을 때 입출력 작업의 대상이 되는 페이지가 다른 프로세스에 의해 페이지 아웃 될 수 있다.

그리고 그 프로세스가 큐의 맨 앞으로 이동해 실행되면, 페이지 아웃된 주소를 대상으로 I/O가 일어난다.

이 문제의 해결법은,

1. 사용자 공간에는 입출력을 행하지 않는것
2. 페이지를 메모리에 잠근하는 것

# 9.10 운영체제의 예

## 9.10.1 Windows XP

## 9.10.2 Solaris

